import asyncio
import time
from dotenv import load_dotenv
from openai import AsyncOpenAI
from pydantic import BaseModel

# Const Parameters
WAIT_TIME = 3 # (seconds) the time to wait between checking whether the LLM's response is complete
MAX_NUM_WAITS = 1000 # sets wait time for timeout from waiting on model response


# TODO: add validation Annotated to class model
class AssistantSession(BaseModel):
  """
  A class containing all the information to reference a session

  Attributes
  ----------
  assistant_id : str
    ID attribute for an openai assistant object
  thread_id : str
    ID attribute for an openai thread object
  """

  assistant_id: str
  thread_id: str

class AssistantSessionMessage(AssistantSession):
  """
  A class containing a session with a message, inherited from AssistantSession
  
  Extra Attributes
  ----------
  message : str
    A string of the message send to the session
  """
  message: str

# Error

class OpenAIError(Exception):
  """A parent class for the different types of errors the openai API can raise"""
  pass

class OpenAIErrorFailed(OpenAIError):
  """A child class for the failed error the openai API can raise"""
  pass
class OpenAIErrorCancelled(OpenAIError):
  """A child class for the cancelled error the openai API can raise"""
  pass

class OpenAIErrorExpired(OpenAIError):
  """A child class for the expired error the openai API can raise"""
  pass

# Initialization commands
load_dotenv()
client = AsyncOpenAI()

async def initialize_conversation():
  """Creates and returns relevant ids for a session
  
  Returns
  -------
  AssistantSession
    IDs for newly created assistant and thread objects
  """
  
  # Create the assistant
  assistant = await client.beta.assistants.create(
    name="Personal Assistant",
    instructions="You are a personal assistant whose role is to help the user complete their tasks and to entertaing the user via conversation.",
    model="gpt-3.5-turbo-1106",
  )

  # Create the thread
  thread = await client.beta.threads.create()

  # Add the ids of the newly created assistand and thread to a new AssistantSession object
  new_session = AssistantSession(assistant_id=assistant.id,thread_id=thread.id)

  return new_session


async def continue_conversation(assistant_message):
  """Takes session information and a new message from the user and returns a response from the LLM
  
  Parameters
  ----------
  current_session : AssistantSession
    IDs for assistant and thread objects of conversation
  next_message : str
    A new message from the user
    
  Returns
  -------
  str
    A response generated by the Asssistant LLM
  """

  # Unpack current_session for ease of access
  threadId = assistant_message.thread_id
  assistantId = assistant_message.assistant_id
  next_message = assistant_message.message

  # Adds the user's message to the thread
  await client.beta.threads.messages.create(
    thread_id=threadId, role="user", content=next_message
  )

  # Makes the LLM start generating its response
  run = await client.beta.threads.runs.create(
    thread_id=threadId, assistant_id=assistantId
  )

  # Waits for the LLM to finish generating its response
  num_waits = 0

  while num_waits < MAX_NUM_WAITS:
    # Check the status of the LLM's response generation
    run = await client.beta.threads.runs.retrieve(
      thread_id=threadId, run_id=run.id
    )

    # Takes action based on the status
    match run.status:
      case "requires_action": # This means that a tool/function needs to be called. Will implement once we have at least one tool. Should probably be implemented as its own function
        continue
      case "cancelled":
        raise OpenAIErrorCancelled(run.last_error.message)
      case "expired":
        raise OpenAIErrorExpired(run.last_error.message)
      case "failed":
        raise OpenAIErrorFailed(run.last_error.message)
      case "completed": # The LLM is done generating its response
        break
      case _ :
        num_waits += 1
        time.sleep(WAIT_TIME)
        
  # Grabs the LLM's response from the end of the threatd
  messages = await client.beta.threads.messages.list(thread_id=threadId)
  response = messages.data[0].content[0].text.value

  return response


async def end_conversation(assistant_to_delete):
  """Deletes session information for when the session is over
  
  Parameters
  ----------
  assistant_to_delete : AssistantSession
    IDs of the session to be deleted
  """

  # Attempts to delete the assistant and thread whose ids are contained in the session information and stores the result of the attempt
  thread_deleted = await client.beta.threads.delete(assistant_to_delete.thread_id)
  assistant_deleted = await client.beta.assistants.delete(assistant_to_delete.assistant_id)
  deleted_both = thread_deleted.deleted and assistant_deleted.deleted

  # Returns True iff both are successfully deleted
  return deleted_both
